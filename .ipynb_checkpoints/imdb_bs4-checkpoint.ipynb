{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e42766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import cv2, urllib, numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acec005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create scraper class \n",
    "class IMDBScraper():\n",
    "    \"\"\"This class is built using bs4 to extract data from the IMDB website. \n",
    "       This calss takes number of pages as in input and it then has the following methods: \n",
    "       get_movie_info updates the movies dataframe with useful scraped information like movie title, description etc.\n",
    "       get_movie_images updates the dataframe with local their local paths and saves the images locally\n",
    "       save_data saves the dataframe as a json file\"\"\"\n",
    "    #contructor method \n",
    "    def __init__(self, page_num):\n",
    "        self.urls = {}\n",
    "        self.pages = {}\n",
    "        self.movie_info = {}\n",
    "        self.movies_dataframe = pd.DataFrame()\n",
    "        self.movie_links = {}\n",
    "        self.page_num = page_num\n",
    "        \n",
    "        #string concatenation to format URL to load the \n",
    "        #correct number of movies for every page and storing the result as a dictionary \n",
    "        #same for pages and movie links \n",
    "        i = 0 \n",
    "        for page in range(1,50*page_num + 1,50):\n",
    "            i += 1 \n",
    "            self.urls[\"page_num: {}\".format(i)] = 'https://www.imdb.com/search/title/?genres=horror&start={}&explore=title_type,genres&ref_=adv_nxt'.format(page)\n",
    "            self.pages[\"page_num: {}\".format(i)] = BeautifulSoup(requests.get(self.urls[\"page_num: {}\".format(i)]).text, \"html.parser\") \n",
    "            self.movie_links[\"page_num: {}\".format(i)] = ['https://www.imdb.com' + item.find_all('a')[0].attrs['href'] for item in self.pages[\"page_num: {}\".format(i)].find_all(attrs={'class':'lister-item-header'})]\n",
    "            \n",
    "\n",
    "    #define function for extracting movie data    \n",
    "    def get_movie_info(self):\n",
    "\n",
    "        list_of_pages = list(self.pages.values())\n",
    "        #using list comprehension to extract each html block of movie inofrmation from each page \n",
    "        for page_item in list_of_pages:\n",
    "            movie_data = [item for item in page_item.find_all(attrs={'class':'lister-item mode-advanced'})] \n",
    "            \n",
    "            #iterating through each html block \n",
    "            for k in range(len(movie_data)):\n",
    "                #splitting the html block so each line is an element of the list\n",
    "                movie = str(movie_data[k]).split('\\n')\n",
    "\n",
    "\n",
    "                #defining a dictionary to save movies \n",
    "                movie_dict = {}\n",
    "                #iterating through each element to store movie information in a dictionary\n",
    "                for j in range(len(movie)):\n",
    "                    i = movie[j]    \n",
    "                    if ('a href=\"/title/' in i) and ('img' in i): \n",
    "                        movie_dict['movie_title'] = i[i.index('img alt=') + 9: i.index('\" class=')]\n",
    "                        movie_dict['movie_image'] = i[i.index('loadlate=\"https') + 10: i.index('\" src=\"https:')].replace('UX67_CR0,0,67,98_AL_','')\n",
    "                    elif 'movie_title' not in movie_dict:\n",
    "                        movie_dict['movie_title'] = None\n",
    "                        movie_dict['movie_image'] = None \n",
    "                    if 'lister-item-year text-muted unbold' in i:\n",
    "                        movie_dict['release_date'] = i[49 :i.index('</span>')]\n",
    "                    elif 'release_date' not in movie_dict: \n",
    "                        movie_dict['release_date'] = None \n",
    "                    if '<span class=\"certificate' in i: \n",
    "                        movie_dict['certificate'] = i[26:i.index('</span>')]\n",
    "                    elif 'certificate' not in movie_dict: \n",
    "                        movie_dict['certificate'] = None \n",
    "                    if 'span class=\"runtime\"' in i: \n",
    "                        movie_dict['duration'] = i[22:i.index('</span>')]\n",
    "                    elif 'duration' not in movie_dict: \n",
    "                        movie_dict['duration'] = None \n",
    "                    if '<span class=\"genre\">' in i:\n",
    "                        i = movie[j + 1]\n",
    "                        movie_dict['genre'] = i[:i.index('            </span>')]\n",
    "                    elif 'genre' not in movie_dict: \n",
    "                        movie_dict['genre'] = None \n",
    "                    if '<div class=\"inline-block ratings-imdb-rating\" data-value=' in i: \n",
    "                        movie_dict['rating'] = i[58:i.index('\" name=\"ir\"')]\n",
    "                    elif 'rating' not in movie_dict: \n",
    "                        movie_dict['rating'] = None\n",
    "                    if '<p class=\"\">' in i:\n",
    "                        i = movie[j - 1]\n",
    "                        movie_dict['description'] = i[:i.index('</p>')]\n",
    "                    elif 'description' not in movie_dict: \n",
    "                        movie_dict['description'] = None \n",
    "                    if '<p class=\"sort-num_votes-visible\">' in i: \n",
    "                        i = movie[j + 2]\n",
    "                        movie_dict['votes'] = i[18:i.index('\" name=\"nv\">')]\n",
    "                    elif 'votes' not in movie_dict: \n",
    "                        movie_dict['votes'] = None\n",
    "\n",
    "\n",
    "\n",
    "                if ('    Director:' in movie) or ('    Directors:'  in movie):\n",
    "                    movie_dict['directors'] = ''\n",
    "                    try:\n",
    "                        try:\n",
    "                            movie = movie[movie.index('    Directors:') + 1:movie.index('    Stars:')]\n",
    "                        except:\n",
    "                            try:\n",
    "                                movie = movie[movie.index('    Directors:') + 1:movie.index('    Star:')]\n",
    "                            except:\n",
    "                                movie = movie[movie.index('    Directors:') + 1:]\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        try:\n",
    "                            movie = movie[movie.index('    Director:') + 1:movie.index('    Stars:')]\n",
    "                        except:\n",
    "                            try:\n",
    "                                movie = movie[movie.index('    Director:') + 1:movie.index('    Star:')]\n",
    "                            except:\n",
    "                                movie = movie[movie.index('    Director:') + 1:]\n",
    "\n",
    "\n",
    "                    for j in range(len(movie)):\n",
    "                        i = movie[j]  \n",
    "                        if '<a href=\"/name/' in i: \n",
    "                            movie_dict['directors'] = ','.join([movie_dict['directors'], i[i.index('/\">') + 3: i.index('</a>')]])\n",
    "                    movie_dict['directors'] = movie_dict['directors'][1:]\n",
    "                elif 'directors' not in movie_dict:\n",
    "                    movie_dict['directors'] = None\n",
    "\n",
    "               #resetting movie list     \n",
    "                movie = str(movie_data[k]).split('\\n')\n",
    "\n",
    "                if ('    Stars:' in movie) or ('    Star:'  in movie):\n",
    "                    movie_dict['stars'] = ''\n",
    "                    try:\n",
    "                        movie = movie[movie.index('    Stars:') + 1:]\n",
    "                    except: \n",
    "                        movie = movie[movie.index('    Star:') + 1:]\n",
    "                    for j in range(len(movie)):\n",
    "                        i = movie[j] \n",
    "                        if '<a href=\"/name/' in i:\n",
    "                            movie_dict['stars'] = ','.join([movie_dict['stars'], i[i.index('/\">') + 3: i.index('</a>')]])\n",
    "                    movie_dict['stars'] = movie_dict['stars'][1:]\n",
    "                elif 'stars' not in movie_dict:\n",
    "                    movie_dict['stars'] = None       \n",
    "                #appends new dictionary to the existing movie dataframe\n",
    "                self.movies_dataframe = pd.concat([self.movies_dataframe, pd.DataFrame(movie_dict, index = [k])], axis = 0).reset_index(drop = True)   \n",
    "    \n",
    "    #defining a function to scrape movie images\n",
    "    def get_movie_images(self):\n",
    "        #opens URL for each movie in the dataframe and stores them as an object \n",
    "        movie_images = [urllib.request.urlopen(url) for url in self.movies_dataframe['movie_image']]\n",
    "        #empty list to store local movie paths \n",
    "        movie_paths = []\n",
    "        image_num = 0 \n",
    "        #iterate through every URL object\n",
    "        for image in movie_images: \n",
    "            #converts the URL object into an image array \n",
    "            image_array = np.asarray(bytearray(image.read()))\n",
    "            #converts image array into an image matrix\n",
    "            img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "            #converting the format of image from BGR to RGB so the colours in the correct format \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            #saves the image into the local directory \n",
    "            cv2.imwrite('movie_images/' + 'movie_number_' + str(image_num) + '.jpg', img)\n",
    "            #saves paths of the saved image in movie paths list \n",
    "            movie_paths.append('movie_images/' + 'movie_number_' + str(image_num) + '.jpg')\n",
    "            \n",
    "            image_num += 1 \n",
    "        #appends the local movie paths to the dataframe     \n",
    "        self.movies_dataframe[\"movies_local_paths\"] = movie_paths\n",
    "            \n",
    "        \n",
    "    #defines function to save dataframe as a json file    \n",
    "    def save_data(self):\n",
    "        self.movies_dataframe.to_json('imdb_data.json', indent = 4)\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1730f3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating an object with chosen number of pages \n",
    "scraper_object = IMDBScraper(page_num = 1)\n",
    "\n",
    "#scrape movie info \n",
    "scraper_object.get_movie_info()\n",
    "#scrape movie images\n",
    "scraper_object.get_movie_images()\n",
    "#display the dataframe\n",
    "scraper_object.movies_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876e3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves dataframe as a json file \n",
    "scraper_object.save_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
